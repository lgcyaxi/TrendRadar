# Changelog v5.3.x

**Release Period**: 2026-01-20

## Overview

The 5.3.x series focuses on report deduplication improvements and configurable AI analysis thresholds.

---

## v5.3.8 - Refactor Extensions to Use Main AI Client (2026-01-22)

Consolidated AI client usage across extensions and cleaned up multi-platform source display.

### Changed
- **Unified AI client architecture**
  - Both `report_dedupe` and `wework_compact` now use the main AI client via `extensions.ai_client`
  - Removed standalone `ollama_client.py` from `report_dedupe` extension
  - Simplified fallback logic when AI client is unavailable

- **Cleaner multi-platform source display**
  - Removed " / " separator between platform links in source header
  - Platforms now display as adjacent clickable badges (e.g., `凤凰网` `百度热搜`)
  - Title links preserved (original behavior maintained)

### Fixed
- **Missing `_build_prompt` method in NewTitlesHandler**
  - Added prompt template and `_build_prompt` method for AI summary generation
  - Fixed error when using LiteLLM AIClient for new_titles section

### Removed
- `extensions/report_dedupe/ollama_client.py` - Functionality now provided by main AI client
- Unused CSS and HTML injection code from report_dedupe extension

### Files Changed

| File | Description |
|------|-------------|
| `extensions/report_dedupe/__init__.py` | Simplified to only remove " / " separators in after_render |
| `extensions/report_dedupe/report_dedupe.py` | Removed OllamaClient import and fallback |
| `extensions/report_dedupe/ollama_client.py` | Deleted (using main AI client) |
| `extensions/wework_compact/handlers/new_titles.py` | Added `_build_prompt` method |

---

## v5.3.7 - Improve WeWork Compact Format (2026-01-22)

Improved wework_compact extension format with cleaner layout and AI briefing integration.

### Changed
- **NewTitles format with AI briefing**
  - Changed section title from "本日新增" to "今日热点"
  - Header format: "今日热点: 共发现 X 条热点新闻"
  - AI core_trends displayed as briefing paragraph between header and title list
  - Removed duplicate "没有新增新闻" message

- **Removed separate news_briefing section**
  - AI briefing functionality merged into new_titles handler
  - Simplified section order: new_titles → current_list → standalone
  - Removed news_briefing handler and related config

- **Fixed AI content duplication**
  - Disabled `include_ai_analysis` in current_list section
  - AI analysis now only appears in new_titles section
  - Removed debug print statements

### Files Changed

||| File | Description |
|------|-------------|-------------|
| `-` | `extensions/wework_compact/handlers/news_briefing.py` | Removed (merged into new_titles) |
| `~` | `extensions/wework_compact/__init__.py` | Removed news_briefing handler |
| `~` | `extensions/wework_compact/handlers/__init__.py` | Removed NewsBriefingHandler export |
| `~` | `extensions/wework_compact/handlers/new_titles.py` | Improved format with AI briefing |

---

## v5.3.6 - Fix AI Config and Mock Mode Issues (2026-01-21)

Fix AI configuration reading and notification mock mode display issues.

### Fixed
- **AI config not reading from main config when use_main_config: true**
  - When `ai.use_main_config` was set to `true`, the extension incorrectly returned `None`
  - Now properly reads `AI.API_BASE` and `AI.MODEL` from main config
  - Creates OllamaClient using main config's Ollama server settings

- **Notification mock mode not showing content**
  - When `notification_mock_mode: true` was set but no extension handled the send
  - Fallback mock mode now displays the actual notification content
  - Shows batched content with proper formatting for text/markdown modes
  - Displays each batch separately for easy review

### Changed
- **Updated _get_ollama_client method**
  - Now accepts `main_config` parameter for accessing main config AI settings
  - Properly handles `use_main_config: true` case by reading from main config
  - Added detailed logging for AI configuration source

### Files Changed

|| File | Description |
||------|-------------|
|| `extensions/wework_compact/handlers/new_titles.py` | Fixed AI config reading from main config |
|| `trendradar/notification/dispatcher.py` | Improved mock mode to show content |

---

## v5.3.5 - Use Dedicated Ollama Config for WeWork Compact (2026-01-21)

Consistent AI configuration pattern with report_dedupe extension using local Ollama server.

### Changed
- **Unified AI configuration approach**
  - WeWork Compact now uses dedicated `ollama` config section like report_dedupe
  - Removed dependency on main config `AI_ANALYSIS` settings
  - Added `ollama.base_url` and `ollama.model` in wework_compact.yaml
  - Set `ai.use_main_config: false` by default to use dedicated Ollama config

### Added
- **New ollama_client.py module**
  - Simple Ollama client for generating news summaries
  - Loads prompt from configurable prompt file
  - Supports custom prompt template with fallback to embedded default
  - Consistent with report_dedupe's OllamaClient pattern

### Fixed
- **AI summary generation**
  - Now uses local Ollama server instead of cloud API (OpenAI/DeepSeek)
  - Eliminates API key configuration issues
  - More reliable for internal/private deployment

### Config Example
```yaml
# In config/extensions/wework_compact.yaml
ai:
  use_main_config: false  # Use dedicated ollama section below
  prompt_file: "wework_compact_prompt.txt"

ollama:
  base_url: "http://10.0.0.163:11434"
  model: "qwen2.5:14b-instruct"
  timeout: 60
```

### Files Changed

|| File | Description |
||------|-------------|
|| `config/extensions/wework_compact.yaml` | Added dedicated ollama section |
|| `extensions/wework_compact/ollama_client.py` | New Ollama client module |
|| `extensions/wework_compact/handlers/new_titles.py` | Use OllamaClient instead of HTTP requests |

---

## v5.3.4 - Fix AI Provider Detection for WeWork Compact (2026-01-21)

Fix AI summary generation in WeWork Compact extension by correctly detecting provider from MODEL name.

### Fixed
- **AI summary generation using wrong API endpoint**
  - When MODEL was set to "deepseek/deepseek-chat", the code still used OpenAI API endpoint
  - Caused 401 Unauthorized errors because OpenAI API key was being used for DeepSeek API
  - Root cause: `provider` defaulted to `'openai'` instead of extracting from MODEL name

### Changed
- **Extract provider from MODEL field**
  - Now parses MODEL field (e.g., "deepseek/deepseek-chat") to extract provider
  - Format: `provider/model-name` - provider is extracted from the part before "/"
  - Falls back to 'openai' only if MODEL doesn't contain "/" separator
  - Added detailed logging for AI configuration and request debugging

### Files Changed

|| File | Description |
||------|-------------|
|| `extensions/wework_compact/handlers/new_titles.py` | Extract provider from MODEL name, added debug logging |

---

## v5.3.3 - WeWork Message Splitting & Report Deduplication Integration (2026-01-20)

Fixes for WeWork message delivery and improved integration between report deduplication and HTML generation.

### Fixed
- **WeWork messages exceeding API limit**
  - Messages over 4096 characters were being rejected by WeWork API
  - Added automatic message splitting with `WEWORK_MSG_LIMIT` of 4000 characters
  - Messages are split at section boundaries first, then by lines if needed
  - Each chunk is sent as a separate API call

### Added
- **Message chunking functions**
  - Added `split_message_by_sections()` for splitting content by section separators
  - Added `_split_by_lines()` helper for splitting long lines when necessary
  - Updated mock mode to display all chunks with progress indicator (e.g., "[1/3]")
  - Logs and displays chunk count when sending multi-chunk messages

### Changed
- **Report deduplication applied before HTML generation**
  - Extension transforms (like report deduplication) now applied before HTML generation
  - Ensures HTML reports reflect deduplicated content
  - Prevents duplicate content from appearing in HTML archives

- **Support for processed new_titles format**
  - `prepare_report_data()` now handles both dict and list formats for new_titles
  - List format (from deduplication) is used directly without re-filtering
  - Maintains compatibility with existing filtering logic for original dict format

### Files Changed

|| File | Description |
||------|-------------|
|| `extensions/wework_compact/__init__.py` | Added message splitting for long WeWork messages |
|| `trendradar/__main__.py` | Applied extension transforms before HTML generation |
|| `trendradar/report/generator.py` | Support list format for new_titles |
|| `pixi.lock` | Dependency updates |

---

## v5.3.2 - Cross-Source Deduplication for New Titles (2026-01-20)

Enhancement to report deduplication by adding cross-source deduplication for the new_titles section.

### Fixed
- **New titles not deduplicated across sources**
  - Previously, titles in the new_titles section were not deduplicated
  - Each source's new titles were kept separate, leading to duplicate content
  - Cross-source deduplication now applies the same algorithm as the main stats section

### Added
- **New `_dedupe_new_titles` function**
  - Flattens all titles from all sources in new_titles
  - Applies same similarity detection and merging logic as main deduplication
  - Returns unified merged list with "综合来源" as the source name
  - Maintains compatibility with expected report structure

### Changed
- **Updated early return logic in `transform_report_data`**
  - Now checks for both stats AND new_titles before early return
  - Ensures new_titles deduplication is always processed when present

### Config Example
```yaml
dedupe:
  new_titles: true  # Enable cross-source deduplication for new_titles
```

---

## v5.3.1 - Configurable Dedupe Candidate Floor (2026-01-20)

Fix report deduplication missing semantically similar Chinese news with different wording.

### Fixed
- **Report deduplication missing similar titles**
  - Pairs like "日本U23男足取胜韩国杀入决赛" and "日本击败韩国晋级U23亚洲杯决赛" were not merged
  - Root cause: `candidate_floor` filter was too aggressive (0.51) blocking AI from checking borderline cases
  - Jaccard similarity 0.35 < 0.51 meant AI never analyzed these semantically identical titles

### Changed
- **Added configurable `candidate_floor_multiplier`**
  - New config option: `similarity.candidate_floor_multiplier` (default: 0.35)
  - Formula: `candidate_floor = max(0.2, threshold * multiplier)`
  - Lower value = more AI checks (catches more duplicates but uses more tokens)
  - Previous hardcoded value of 0.6 was too strict for Chinese news with synonyms

### Config Example
```yaml
similarity:
  threshold: 0.85
  candidate_floor_multiplier: 0.35  # New: controls AI check floor
```

---
